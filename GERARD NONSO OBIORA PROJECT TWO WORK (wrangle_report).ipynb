{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wangling and Analyze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, the dataset 'WeRateDogs' was wrangled. Because real-world data rarely comes clean, data will thus be gathered (based on WeRateDogs) from a variety of sources with the end goal of analyzing and visualizing the collated information afterwards.\n",
    "The Wrangling will follow this format:Data Gathering, Assessing the Data, Cleaning the Data.\n",
    "\n",
    "\n",
    "The jupyter notebook **[GERARD NONSO OBIORA PROJECT TWO WORK (wrangle_act)]** has the project code and the aim here is to communicate my wrangling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering data is the first step in data wrangling. Before gathering, we have no data, and after it, we do.\n",
    "\n",
    "Data was gathered from **three sources**:\n",
    "1. The WeRateDogs Twitter archive (twitter_archive_enhanced.csv) as given by Udacity (it is a CSV document) and downloaded manually.\n",
    "2. The tweet image predictions (image_predictions.tsv) downloaded using Requests library from Udacity servers.\n",
    "3. Additional data (such as retweet count and favorite ('like') count) by querying Twitter API (approval was granted me by Twitter for a developer account in less than 24hours using my already existing normal twitter account and the instructions to follow in setting up a developer account by Udacity) with the aid of Tweepy library (and my consumer_key, consumer_token, access_key and access_secret codes for the API object) and thereafter, stored the queried data in a file (tweet_json.txt). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Assessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I was done gathering the needed data, I proceeded to assess the data both visually and programmatically. I did so in order to detect quality and tidiness issues of the gathered data.\n",
    "Visual assessment involves looking at your dataset in its entirety in whatever program you like while programmatic assessment involves using functions and methods to reveal something about your data's quality and tidiness. On the other hand, quality issues has to do with the data content and tidiness issues has to do with the structure of the data that prevents easy analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the **quality issues** I observed are:\n",
    "\n",
    "**A. twitter_archive_data**\n",
    "1. There are retweets sometimes\n",
    "2. There are incorrect dog names such as 'a'.\n",
    "3. tweet_id is in 'int' but 'object' is more ideal and timestamp is in 'object' instead of 'datetime' format.\n",
    "4. There are tweets with no image (only tweets with images are needed).\n",
    "\n",
    "**B. image_predictions**\n",
    "1. tweet_id is in 'int' but 'object' is more ideal.\n",
    "2. There are rows with 'false' stated. 'It is not a type of dog' is what its saying (p1_dog, p2_dog, p3_dog columns).\n",
    "3. The names of the breed of dogs have inconsistent letter case (some are in proper case, some are in small case).\n",
    "\n",
    "**C. additional_twitterdata**\n",
    "1. Values of each of the columns (friends_count, user_id, join_date, statuses_count) are same and not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the **tidiness issues** I observed are:\n",
    "\n",
    "**A. twitter_archive_data**\n",
    "1. There are columns with NaN values and thus, not needed.\n",
    "2. tweet_id column are in all three datasets and thus, should be used to combine all three into a single dataset.\n",
    "3. The 'puppo', 'pupper', 'floofer' and 'doggo' columns are separate instead of a single column (as they are dog stages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, all of the issues (quality and tidiness) stated while assessing (Assessing Data above) was cleaned (using Define, Code and Test process respectively for each cleaning of the issues)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
